{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDilggOXycmO4j0dGp81Fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucia1009/TFG-Plataforma-para-la-prediccion-de-potencia-electrica-generada-en-parques-eolicos/blob/desarrollo/modelos/ST_Santiago.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "metadata": {
        "id": "Pp9qou2f6RJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------- DATOS ANTERIORES Y POSTERIORES --------------------------------------------------------------------#\n",
        "# Definición de los hiperparámetros INPUT_LENGTH y OUTPUT_LENGTH\n",
        "INPUT_LENGTH = 144    # Registros de 24 h anteriores a la entrada\n",
        "OUTPUT_LENGTH = 6    # El modelo va a predecir 60 min a futuro\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------#"
      ],
      "metadata": {
        "id": "KY2LPBfW61p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAeINyWB5zY1"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(serie, tr_size=0.8, vl_size=0.1, ts_size=0.1 ):\n",
        "    # Definir número de datos en cada subserie\n",
        "    N = serie.shape[0]\n",
        "    Ntrain = int(tr_size*N)  # Número de datos de entrenamiento\n",
        "    Nval = int(vl_size*N)    # Número de datos de validación\n",
        "    Ntst = N - Ntrain - Nval # Número de datos de prueba\n",
        "\n",
        "    # Realizar partición\n",
        "    train = serie[0:Ntrain]\n",
        "    val = serie[Ntrain:Ntrain+Nval]\n",
        "    test = serie[Ntrain+Nval:]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "train, val, test = train_val_test_split(datos_filtrado)\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def escalar_datos(datos):\n",
        "  scaler = MinMaxScaler()\n",
        "  scaled_datos = scaler.fit_transform(datos)\n",
        "\n",
        "  return  scaled_datos, scaler\n",
        "\n",
        "def train_val_test_split_scaled(datos):\n",
        "  train, val, test = train_val_test_split(datos)\n",
        "\n",
        "  train_scaled, scaler_train = escalar_datos(train)\n",
        "  val_scaled, scaler_val = scaler.transform(val)\n",
        "  test_scaled, scaler_test = scaler.transform(test)\n",
        "\n",
        "  return train_scaled, val_scaled, test_scaled, scaler_train, scaler_val, scaler_test\n",
        "\n",
        "def get_target(datos):\n",
        "  y=datos['WF_Power']\n",
        "  X=datos.drop(columns=['WF_Power'])\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "-HLoYFJf62c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hacer_y_entrenar_modelo():\n",
        "    N_UNITS = 128\n",
        "\n",
        "    modelo = Sequential()\n",
        "    modelo.add(LSTM(N_UNITS, input_shape=(INPUT_LENGTH, X_train_s.shape[1])))\n",
        "    modelo.add(Dense(y_train_s.shape[1], activation='linear'))\n",
        "    modelo.compile(optimizer=RMSprop(), loss='mse', metrics=['mae', 'mse', 'R2Score'])\n",
        "    modelo.summary()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE = 512\n",
        "\n",
        "    # Create a TimeseriesGenerator\n",
        "    train_generator = TimeseriesGenerator(\n",
        "        X_train_s, y_train_s, length=INPUT_LENGTH, batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # Fit the model using the generator\n",
        "    model.fit_generator(train_generator,epochs= EPOCHS)\n",
        "\n",
        "    return modelo"
      ],
      "metadata": {
        "id": "9CAOkkSh9UCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predice(scaler_y, X_test_s, y_test_s):\n",
        "  # test_generator = TimeseriesGenerator(\n",
        "  #       X_test_s, y_test_s, length=INPUT_LENGTH, batch_size=BATCH_SIZE\n",
        "  #   )\n",
        "\n",
        "  # preds = modelo.predict(test_generator)\n",
        "  preds = modelo.predict(X_test_s)\n",
        "\n",
        "  preds = scaler_y.inverse_transform(preds)\n",
        "  # y_test_s = scaler_y.inverse_transform(y_test_s)\n",
        "\n",
        "  # predicciones = pd.DataFrame(preds, columns=y_test.columns)\n",
        "  # y_test_df = pd.DataFrame(y_test, columns=y_test.columns)\n",
        "\n",
        "  return preds\n",
        "\n",
        "  scores={}\n",
        "  scores['rmse'] = math.sqrt(mean_squared_error(y_test_s, preds))\n",
        "  scores['mae'] = mean_absolute_error(y_test_s, preds)\n",
        "  scores['r2']= r2_score(y_test_s, preds)\n",
        "  scores['max_error']= max_error(y_test_s, preds)"
      ],
      "metadata": {
        "id": "smeH_WIn_OoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}